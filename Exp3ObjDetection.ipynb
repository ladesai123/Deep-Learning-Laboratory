{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dffa0863-2666-4e83-8ef0-6a58e53bbc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Number of GPUs: 8\n",
      "GPU 0: NVIDIA H200\n",
      "GPU 1: NVIDIA H200\n",
      "GPU 2: NVIDIA H200\n",
      "GPU 3: NVIDIA H200\n",
      "GPU 4: NVIDIA H200\n",
      "GPU 5: NVIDIA H200\n",
      "GPU 6: NVIDIA H200\n",
      "GPU 7: NVIDIA H200\n",
      "\n",
      "Your target device is: cuda:3\n",
      "Success! Can use cuda:3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available at all\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "# Check how many GPUs are available\n",
    "print(\"Number of GPUs:\", torch.cuda.device_count())\n",
    "\n",
    "# Get the name of all GPUs\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "\n",
    "# This is the most important check: See if device 3 exists\n",
    "try:\n",
    "    device = torch.device(f'cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"\\nYour target device is: {device}\")\n",
    "    # A quick test to see if we can use it\n",
    "    test_tensor = torch.tensor([1.0, 2.0]).to(device)\n",
    "    print(\"Success! Can use cuda:3\")\n",
    "except Exception as e:\n",
    "    print(f\"Error with cuda:3: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2906f2-7c9e-430b-9fcb-5a3b579358ae",
   "metadata": {},
   "source": [
    "## 1.Installing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d9ba9cd-57e1-4d55-98f9-2c335c236d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow\n",
    "#!pip install opencv-python\n",
    "#!pip install scikit-learn\n",
    "#!pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de963ea-89c5-4c89-89c6-a27131b1c90a",
   "metadata": {},
   "source": [
    "## Importing the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b07312b-b5a1-4e6a-a3d9-af3b3767f96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 10:28:10.841169: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-21 10:28:10.854118: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1755752290.867909 3965512 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1755752290.871838 3965512 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1755752290.882883 3965512 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755752290.882902 3965512 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755752290.882903 3965512 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755752290.882904 3965512 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-21 10:28:10.887661: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/SASTRA-NEW-CLUSTER/apps/anaconda3/envs/LABENV/lib/python3.12/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07f412bc-67b1-42a3-ae3e-2be1b25f0d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled memory growth for 8 GPU(s).\n"
     ]
    }
   ],
   "source": [
    "# --- NEW FIX: CONFIGURE GPU MEMORY GROWTH ---\n",
    "# This code checks if a GPU is available and tells TensorFlow to only allocate\n",
    "# memory as it's needed, instead of grabbing it all at once.\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    print(f\"Enabled memory growth for {len(gpus)} GPU(s).\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "# -----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39c9aeb7-f484-4166-99cc-3cba32121c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_xml(xml_file):\n",
    "    \"\"\"Parses an XML file to extract bounding boxes and labels.\"\"\"\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    boxes, labels = [], []\n",
    "   \n",
    "    for obj in root.findall(\"object\"):\n",
    "        label = obj.find(\"name\").text\n",
    "        bbox = obj.find(\"bndbox\")\n",
    "        xmin = int(bbox.find(\"xmin\").text)\n",
    "        ymin = int(bbox.find(\"ymin\").text)\n",
    "        xmax = int(bbox.find(\"xmax\").text)\n",
    "        ymax = int(bbox.find(\"ymax\").text)\n",
    "       \n",
    "        boxes.append([xmin, ymin, xmax, ymax])\n",
    "        labels.append(label)\n",
    "   \n",
    "    return boxes, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93719615-fab2-4733-bc0b-df09c2090ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(folder_path):\n",
    "    \"\"\"Loads all images and their labels from the dataset folder.\"\"\"\n",
    "    images, all_labels = [], []\n",
    "   \n",
    "    print(f\"Loading dataset from: {folder_path}\")\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            xml_path = os.path.join(folder_path, filename.replace(\".jpg\", \".xml\"))\n",
    "\n",
    "            if os.path.exists(xml_path):\n",
    "                img = cv2.imread(img_path)\n",
    "                # We only need the labels for this classification task\n",
    "                _, label_list = parse_xml(xml_path)\n",
    "\n",
    "                # If an image has multiple objects, we add it multiple times\n",
    "                for label in label_list:\n",
    "                    images.append(img)\n",
    "                    all_labels.append(label)\n",
    "            else:\n",
    "                print(f\"Warning: XML annotation missing for {filename}\")\n",
    "\n",
    "    return images, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "462e96ca-2ae8-44b4-90f8-2081e75954c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from: Object detection dataset/Object detection dataset/train/train\n",
      "Loaded 465 images and 465 labels.\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"Object detection dataset/Object detection dataset/train/train\" \n",
    "\n",
    "images, all_labels = load_dataset(dataset_path)\n",
    "\n",
    "# A quick check to make sure everything loaded correctly\n",
    "print(f\"Loaded {len(images)} images and {len(all_labels)} labels.\")\n",
    "assert len(images) == len(all_labels), \"Mismatch between images and labels!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32a601a2-09d1-467a-8971-7faab514ef3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 classes: ['apple' 'banana' 'orange']\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(all_labels)\n",
    "\n",
    "num_classes = len(label_encoder.classes_)\n",
    "y = tf.keras.utils.to_categorical(encoded_labels, num_classes=num_classes)\n",
    "\n",
    "print(f\"Found {num_classes} classes: {label_encoder.classes_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9fd844e-d155-4b45-b2a1-3c8a7935efe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing images to 128x128.\n"
     ]
    }
   ],
   "source": [
    "# Define the new, smaller image size\n",
    "IMG_SIZE = 128 \n",
    "print(f\"Resizing images to {IMG_SIZE}x{IMG_SIZE}.\")\n",
    "\n",
    "X = np.array([cv2.resize(img, (IMG_SIZE, IMG_SIZE)) for img in images]) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1821f272-46c9-4285-a3d3-7bb8851a9e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 372, Test samples: 93\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}, Test samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07492235-0e67-41fd-9b2a-ad82d5ce3793",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/SASTRA-NEW-CLUSTER/apps/anaconda3/envs/LABENV/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "I0000 00:00:1755752309.770050 3965512 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1612 MB memory:  -> device: 0, name: NVIDIA H200, pci bus id: 0000:1b:00.0, compute capability: 9.0\n",
      "I0000 00:00:1755752309.772872 3965512 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 139253 MB memory:  -> device: 1, name: NVIDIA H200, pci bus id: 0000:43:00.0, compute capability: 9.0\n",
      "I0000 00:00:1755752309.775320 3965512 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 137461 MB memory:  -> device: 2, name: NVIDIA H200, pci bus id: 0000:52:00.0, compute capability: 9.0\n",
      "I0000 00:00:1755752309.778099 3965512 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 101971 MB memory:  -> device: 3, name: NVIDIA H200, pci bus id: 0000:61:00.0, compute capability: 9.0\n",
      "I0000 00:00:1755752309.781402 3965512 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 138361 MB memory:  -> device: 4, name: NVIDIA H200, pci bus id: 0000:9d:00.0, compute capability: 9.0\n",
      "I0000 00:00:1755752309.784718 3965512 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 138351 MB memory:  -> device: 5, name: NVIDIA H200, pci bus id: 0000:c3:00.0, compute capability: 9.0\n",
      "I0000 00:00:1755752309.788110 3965512 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 139253 MB memory:  -> device: 6, name: NVIDIA H200, pci bus id: 0000:d1:00.0, compute capability: 9.0\n",
      "I0000 00:00:1755752309.791217 3965512 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 139253 MB memory:  -> device: 7, name: NVIDIA H200, pci bus id: 0000:df:00.0, compute capability: 9.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57600</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">7,372,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m57600\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m7,372,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m387\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,392,707</span> (28.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,392,707\u001b[0m (28.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,392,707</span> (28.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,392,707\u001b[0m (28.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    # The input_shape must match our new IMG_SIZE\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10903676-74ac-49ca-abb5-b2bb09bdd476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting model training...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1755752312.912616 3967257 service.cc:152] XLA service 0x7f4654005bb0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1755752312.912682 3967257 service.cc:160]   StreamExecutor device (0): NVIDIA H200, Compute Capability 9.0\n",
      "I0000 00:00:1755752312.912688 3967257 service.cc:160]   StreamExecutor device (1): NVIDIA H200, Compute Capability 9.0\n",
      "I0000 00:00:1755752312.912692 3967257 service.cc:160]   StreamExecutor device (2): NVIDIA H200, Compute Capability 9.0\n",
      "I0000 00:00:1755752312.912695 3967257 service.cc:160]   StreamExecutor device (3): NVIDIA H200, Compute Capability 9.0\n",
      "I0000 00:00:1755752312.912697 3967257 service.cc:160]   StreamExecutor device (4): NVIDIA H200, Compute Capability 9.0\n",
      "I0000 00:00:1755752312.912700 3967257 service.cc:160]   StreamExecutor device (5): NVIDIA H200, Compute Capability 9.0\n",
      "I0000 00:00:1755752312.912702 3967257 service.cc:160]   StreamExecutor device (6): NVIDIA H200, Compute Capability 9.0\n",
      "I0000 00:00:1755752312.912705 3967257 service.cc:160]   StreamExecutor device (7): NVIDIA H200, Compute Capability 9.0\n",
      "2025-08-21 10:28:32.964143: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1755752313.285582 3967257 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4922 - loss: 2.0164"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1755752317.121193 3967257 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 217ms/step - accuracy: 0.5112 - loss: 1.8612 - val_accuracy: 0.7204 - val_loss: 0.7721\n",
      "Epoch 2/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7714 - loss: 0.5359 - val_accuracy: 0.8602 - val_loss: 0.5255\n",
      "Epoch 3/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8767 - loss: 0.2975 - val_accuracy: 0.8280 - val_loss: 0.4853\n",
      "Epoch 4/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8602 - loss: 0.3376 - val_accuracy: 0.8280 - val_loss: 0.4130\n",
      "Epoch 5/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9095 - loss: 0.2265 - val_accuracy: 0.8602 - val_loss: 0.4705\n",
      "Epoch 6/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9122 - loss: 0.1813 - val_accuracy: 0.8710 - val_loss: 0.5694\n",
      "Epoch 7/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8995 - loss: 0.2118 - val_accuracy: 0.8602 - val_loss: 0.4434\n",
      "Epoch 8/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8853 - loss: 0.2956 - val_accuracy: 0.8495 - val_loss: 0.6212\n",
      "Epoch 9/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9069 - loss: 0.2285 - val_accuracy: 0.8710 - val_loss: 0.4040\n",
      "Epoch 10/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9302 - loss: 0.1703 - val_accuracy: 0.8495 - val_loss: 0.4385\n",
      "Model training finished.\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model with a smaller batch size\n",
    "print(\"\\nStarting model training...\")\n",
    "history = model.fit(X_train, y_train, \n",
    "                    batch_size=16,  # <--- REDUCED BATCH SIZE\n",
    "                    epochs=10, \n",
    "                    validation_data=(X_test, y_test))\n",
    "print(\"Model training finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64e781e6-1f99-4964-8ec9-52b7d0016fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    \"\"\"Loads and prepares a single image for prediction.\"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    img_resized = cv2.resize(img, (224, 224)) / 255.0\n",
    "    img_expanded = np.expand_dims(img_resized, axis=0) # Add batch dimension\n",
    "    return img_expanded, img # Return preprocessed and original images\n",
    "\n",
    "def visualize_prediction(original_img, predicted_label, confidence):\n",
    "    \"\"\"Draws the predicted label on the image.\"\"\"\n",
    "    # We'll just put the text on the image for this classifier\n",
    "    text = f\"{predicted_label} ({confidence:.2f}%)\"\n",
    "    cv2.putText(original_img, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    \n",
    "    # Display the image\n",
    "    cv2.imshow(\"Prediction\", original_img)\n",
    "    cv2.waitKey(0) # Wait for a key press to close the window\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a07132-bd1b-492d-9a73-3620469484b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 659ms/step\n",
      "\n",
      "--- Prediction Result ---\n",
      "Predicted Label: banana\n",
      "Confidence: 61.12%\n"
     ]
    }
   ],
   "source": [
    "# --- Make sure IMG_SIZE is defined. It should be 128, just like in training. ---\n",
    "IMG_SIZE = 128 \n",
    "\n",
    "# 7.1. Helper Functions for Prediction\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"Loads and prepares a single image for prediction.\"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    # --- THIS IS THE FIX ---\n",
    "    # Ensure we resize to the SAME dimensions the model was trained on.\n",
    "    img_resized = cv2.resize(img, (IMG_SIZE, IMG_SIZE)) / 255.0\n",
    "    img_expanded = np.expand_dims(img_resized, axis=0) # Add batch dimension\n",
    "    return img_expanded, img # Return preprocessed and original images\n",
    "\n",
    "def visualize_prediction(original_img, predicted_label, confidence):\n",
    "    \"\"\"Draws the predicted label on the image.\"\"\"\n",
    "    text = f\"{predicted_label} ({confidence:.2f}%)\"\n",
    "    cv2.putText(original_img, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    \n",
    "    # Display the image\n",
    "    cv2.imshow(\"Prediction\", original_img)\n",
    "    cv2.waitKey(0) # Wait for a key press to close the window\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# 7.2. Make the Prediction\n",
    "# --- IMPORTANT: Change this path to your test image! ---\n",
    "image_path_to_predict = r\"Object detection dataset/Object detection dataset/test/test/orange_86.jpg\" \n",
    "\n",
    "# 1. Preprocess the image using the corrected function\n",
    "processed_img, original_img = preprocess_image(image_path_to_predict)\n",
    "\n",
    "# 2. Get the model's prediction\n",
    "prediction_probabilities = model.predict(processed_img)[0]\n",
    "\n",
    "# 3. Find the class with the highest probability\n",
    "predicted_label_index = np.argmax(prediction_probabilities)\n",
    "confidence = prediction_probabilities[predicted_label_index] * 100\n",
    "predicted_label = label_encoder.inverse_transform([predicted_label_index])[0]\n",
    "\n",
    "print(f\"\\n--- Prediction Result ---\")\n",
    "print(f\"Predicted Label: {predicted_label}\")\n",
    "print(f\"Confidence: {confidence:.2f}%\")\n",
    "\n",
    "# 4. Visualize the result\n",
    "visualize_prediction(original_img, predicted_label, confidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279681b8-7300-479a-9d40-d88b3b38ddf5",
   "metadata": {},
   "source": [
    "# Object Detection Using Bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bda59df9-60d5-4563-8aa7-37e70cf35245",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 10:30:12.622112: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-21 10:30:12.658803: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1755752412.685434 3978607 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1755752412.692998 3978607 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1755752412.714358 3978607 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755752412.714397 3978607 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755752412.714399 3978607 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755752412.714401 3978607 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-21 10:30:12.722485: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/SASTRA-NEW-CLUSTER/apps/anaconda3/envs/LABENV/lib/python3.12/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled memory growth for 8 GPU(s).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Configure GPU for memory growth to prevent memory errors\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    print(f\"Enabled memory growth for {len(gpus)} GPU(s).\")\n",
    "  except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "189a3c8c-2761-4742-977b-e0a9fd6b60bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_xml(xml_file):\n",
    "    \"\"\"Parses an XML file to extract bounding boxes and labels.\"\"\"\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    boxes, labels = [], []\n",
    "    for obj in root.findall(\"object\"):\n",
    "        label = obj.find(\"name\").text\n",
    "        bbox = obj.find(\"bndbox\")\n",
    "        xmin = int(bbox.find(\"xmin\").text)\n",
    "        ymin = int(bbox.find(\"ymin\").text)\n",
    "        xmax = int(bbox.find(\"xmax\").text)\n",
    "        ymax = int(bbox.find(\"ymax\").text)\n",
    "        boxes.append([xmin, ymin, xmax, ymax])\n",
    "        labels.append(label)\n",
    "    return boxes, labels\n",
    "\n",
    "def load_full_dataset(folder_path):\n",
    "    \"\"\"Loads images, their labels, and their bounding boxes.\"\"\"\n",
    "    image_paths, all_labels, all_boxes = [], [], []\n",
    "    print(f\"Loading dataset from: {folder_path}\")\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            xml_path = os.path.join(folder_path, filename.replace(\".jpg\", \".xml\"))\n",
    "            if os.path.exists(xml_path):\n",
    "                # For simplicity, we'll assume one object per image.\n",
    "                # Real-world detectors are more complex.\n",
    "                boxes, labels = parse_xml(xml_path)\n",
    "                if len(boxes) > 0: # Only take single-object images\n",
    "                    image_paths.append(img_path)\n",
    "                    all_labels.append(labels[0])\n",
    "                    all_boxes.append(boxes[0])\n",
    "            else:\n",
    "                print(f\"Warning: XML annotation missing for {filename}\")\n",
    "    return image_paths, all_labels, all_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9ce2b5-03f8-4910-a141-f318cd5a5590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from: Object detection dataset/Object detection dataset/train/train\n",
      "Processing images and normalizing bounding boxes...\n"
     ]
    }
   ],
   "source": [
    "# 1. Load the raw data\n",
    "dataset_path = \"Object detection dataset/Object detection dataset/train/train\"\n",
    "image_paths, text_labels, raw_boxes = load_full_dataset(dataset_path)\n",
    "\n",
    "# 2. Define image size and prepare lists\n",
    "IMG_SIZE = 128\n",
    "processed_images, normalized_boxes = [], []\n",
    "\n",
    "print(\"Processing images and normalizing bounding boxes...\")\n",
    "for i in range(len(image_paths)):\n",
    "    # Read image and get original dimensions\n",
    "    img = cv2.imread(image_paths[i])\n",
    "    h, w, _ = img.shape\n",
    "    \n",
    "    # Resize image and add to list\n",
    "    img_resized = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "    processed_images.append(img_resized)\n",
    "    \n",
    "    # Normalize the bounding box coordinates\n",
    "    xmin, ymin, xmax, ymax = raw_boxes[i]\n",
    "    normalized_boxes.append([xmin/w, ymin/h, xmax/w, ymax/h])\n",
    "\n",
    "# 3. Convert lists to NumPy arrays\n",
    "X_images = np.array(processed_images, dtype=np.float32) / 255.0\n",
    "y_boxes = np.array(normalized_boxes, dtype=np.float32)\n",
    "\n",
    "# 4. Encode labels to categorical format\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(text_labels)\n",
    "y_labels = tf.keras.utils.to_categorical(encoded_labels, num_classes=len(label_encoder.classes_))\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# 5. Split all data into training and testing sets\n",
    "(X_train, X_test, \n",
    " y_labels_train, y_labels_test, \n",
    " y_boxes_train, y_boxes_test) = train_test_split(X_images, y_labels, y_boxes, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Data prepared: {len(X_train)} training samples, {len(X_test)} test samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "709675f6-21f0-4bdd-84dd-b29f4eb10b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1755752459.704895 3978607 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1612 MB memory:  -> device: 0, name: NVIDIA H200, pci bus id: 0000:1b:00.0, compute capability: 9.0\n",
      "I0000 00:00:1755752459.709859 3978607 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 139253 MB memory:  -> device: 1, name: NVIDIA H200, pci bus id: 0000:43:00.0, compute capability: 9.0\n",
      "I0000 00:00:1755752459.713039 3978607 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 137461 MB memory:  -> device: 2, name: NVIDIA H200, pci bus id: 0000:52:00.0, compute capability: 9.0\n",
      "I0000 00:00:1755752459.716379 3978607 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 101973 MB memory:  -> device: 3, name: NVIDIA H200, pci bus id: 0000:61:00.0, compute capability: 9.0\n",
      "I0000 00:00:1755752459.720698 3978607 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 138361 MB memory:  -> device: 4, name: NVIDIA H200, pci bus id: 0000:9d:00.0, compute capability: 9.0\n",
      "I0000 00:00:1755752459.726222 3978607 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 138351 MB memory:  -> device: 5, name: NVIDIA H200, pci bus id: 0000:c3:00.0, compute capability: 9.0\n",
      "I0000 00:00:1755752459.729426 3978607 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 139253 MB memory:  -> device: 6, name: NVIDIA H200, pci bus id: 0000:d1:00.0, compute capability: 9.0\n",
      "I0000 00:00:1755752459.732657 3978607 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 139253 MB memory:  -> device: 7, name: NVIDIA H200, pci bus id: 0000:df:00.0, compute capability: 9.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57600</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bounding_box        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │    <span style=\"color: #00af00; text-decoration-color: #00af00\">230,404</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ class_label (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │    <span style=\"color: #00af00; text-decoration-color: #00af00\">172,803</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m,  │        \u001b[38;5;34m896\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m,    │     \u001b[38;5;34m18,496\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m57600\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bounding_box        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │    \u001b[38;5;34m230,404\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ class_label (\u001b[38;5;33mDense\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │    \u001b[38;5;34m172,803\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">422,599</span> (1.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m422,599\u001b[0m (1.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">422,599</span> (1.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m422,599\u001b[0m (1.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the input layer\n",
    "inputs = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "# Feature extraction layers (the \"backbone\")\n",
    "x = Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "# Head for bounding box regression\n",
    "bbox_output = Dense(4, activation='sigmoid', name='bounding_box')(x)\n",
    "\n",
    "# Head for class label prediction\n",
    "class_output = Dense(num_classes, activation='softmax', name='class_label')(x)\n",
    "\n",
    "# Combine into a single model with two outputs\n",
    "model = Model(inputs=inputs, outputs=[bbox_output, class_output])\n",
    "\n",
    "# Compile the model with two separate loss functions\n",
    "losses = {\n",
    "    \"bounding_box\": \"mean_squared_error\",\n",
    "    \"class_label\": \"categorical_crossentropy\"\n",
    "}\n",
    "model.compile(optimizer='adam', loss=losses, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75b7c8b9-cca8-4aec-bfe9-86363a2c7064",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting object detector training...\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Attr 'Toutput_types' of 'OptionalFromValue' Op passed list of length 0 less than minimum 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      5\u001b[39m y_train_dict = {\n\u001b[32m      6\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbounding_box\u001b[39m\u001b[33m\"\u001b[39m: y_boxes_train,  \u001b[38;5;66;03m# <--- FIX: Changed \"bounding box\" to \"bounding_box\"\u001b[39;00m\n\u001b[32m      7\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mclass_label\u001b[39m\u001b[33m\"\u001b[39m: y_labels_train\n\u001b[32m      8\u001b[39m }\n\u001b[32m      9\u001b[39m y_test_dict = {\n\u001b[32m     10\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbounding_box\u001b[39m\u001b[33m\"\u001b[39m: y_boxes_test,   \u001b[38;5;66;03m# <--- FIX: Changed \"bounding box\" to \"bounding_box\"\u001b[39;00m\n\u001b[32m     11\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mclass_label\u001b[39m\u001b[33m\"\u001b[39m: y_labels_test\n\u001b[32m     12\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m history = model.fit(X_train, y_train_dict,\n\u001b[32m     15\u001b[39m                     validation_data=(X_test, y_test_dict),\n\u001b[32m     16\u001b[39m                     epochs=\u001b[32m5\u001b[39m,\n\u001b[32m     17\u001b[39m                     batch_size=\u001b[32m8\u001b[39m,\n\u001b[32m     18\u001b[39m                     verbose=\u001b[32m1\u001b[39m)\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mModel training finished.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/SASTRA-NEW-CLUSTER/apps/anaconda3/envs/LABENV/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/SASTRA-NEW-CLUSTER/apps/anaconda3/envs/LABENV/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:132\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.multi_step_on_iterator\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;129m@tf\u001b[39m.autograph.experimental.do_not_convert\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmulti_step_on_iterator\u001b[39m(iterator):\n\u001b[32m    131\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.steps_per_execution == \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m tf.experimental.Optional.from_value(\n\u001b[32m    133\u001b[39m             one_step_on_data(iterator.get_next())\n\u001b[32m    134\u001b[39m         )\n\u001b[32m    136\u001b[39m     \u001b[38;5;66;03m# the spec is set lazily during the tracing of `tf.while_loop`\u001b[39;00m\n\u001b[32m    137\u001b[39m     empty_outputs = tf.experimental.Optional.empty(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[31mValueError\u001b[39m: Attr 'Toutput_types' of 'OptionalFromValue' Op passed list of length 0 less than minimum 1."
     ]
    }
   ],
   "source": [
    "print(\"\\nStarting object detector training...\")\n",
    "\n",
    "# Prepare the training and validation data with the CORRECT dictionary keys\n",
    "# The keys must exactly match the output layer names from Step 4.\n",
    "y_train_dict = {\n",
    "    \"bounding_box\": y_boxes_train,  # <--- FIX: Changed \"bounding box\" to \"bounding_box\"\n",
    "    \"class_label\": y_labels_train\n",
    "}\n",
    "y_test_dict = {\n",
    "    \"bounding_box\": y_boxes_test,   # <--- FIX: Changed \"bounding box\" to \"bounding_box\"\n",
    "    \"class_label\": y_labels_test\n",
    "}\n",
    "\n",
    "history = model.fit(X_train, y_train_dict,\n",
    "                    validation_data=(X_test, y_test_dict),\n",
    "                    epochs=5,\n",
    "                    batch_size=8,\n",
    "                    verbose=1)\n",
    "\n",
    "print(\"Model training finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3a3334-73c5-47ed-8831-ed0f99f151f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01430375-813b-4d99-b4aa-7064a80f7ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b47cf9-f1dd-4b07-a76a-762e8b4c672b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
